{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7a7WuSCGBiS"
      },
      "source": [
        "# CHOWDER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTUvo2GGELp"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7K98CEankGG",
        "outputId": "fcd371a8-a7b9-4ca5-8b4e-b3b8fa3c32d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRdeZmxRF6lv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, ConcatDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ym0jJzmGMwX",
        "outputId": "f9617941-0a38-4643-b44b-ad7160752338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEP9wThKGNmv"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA9sRTmAGPbH"
      },
      "outputs": [],
      "source": [
        "processed_data_path = '/content/drive/My Drive/Breast_Cancer_Detection/Processed_Data/'\n",
        "\n",
        "X_dev = np.load(processed_data_path + 'X_dev.npy')\n",
        "y_dev = np.load(processed_data_path + 'y_dev.npy')\n",
        "\n",
        "X_test = np.load(processed_data_path + 'X_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UZ5pixlHaP_"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvD3AJlWHbl6"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.15, stratify=y_dev, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCQyfA4KGiJT"
      },
      "source": [
        "## Standardize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrujd_x7GmCJ"
      },
      "outputs": [],
      "source": [
        "def X_standardize(X_train, X_val, X_test):\n",
        "\n",
        "    feature_mean = np.mean(X_train)\n",
        "    feature_std = np.std(X_train)\n",
        "\n",
        "    X_train_scaled = (X_train - feature_mean) / feature_std\n",
        "    X_val_scaled = (X_val - feature_mean) / feature_std\n",
        "    X_test_scaled = (X_test - feature_mean) / feature_std\n",
        "\n",
        "    return X_train_scaled, X_val_scaled, X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r1BHVpzHwEP"
      },
      "outputs": [],
      "source": [
        "X_train_scaled, X_val_scaled, X_test_scaled = X_standardize(X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypElU9wJJO2X"
      },
      "source": [
        "## Convert to Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHP07ms3I22G"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.Tensor(X_train_scaled)\n",
        "X_val_tensor = torch.Tensor(X_val_scaled)\n",
        "X_test_tensor = torch.Tensor(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FLD-9qYJTJ9"
      },
      "outputs": [],
      "source": [
        "# Delete redundant variables to free up memory\n",
        "del X_train_scaled\n",
        "del X_val_scaled\n",
        "del X_test_scaled\n",
        "del X_train\n",
        "del X_val\n",
        "del X_test\n",
        "del X_dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvkzmqLUJ9o3"
      },
      "source": [
        "## CHOWDER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs8Yoh9SJ_wP"
      },
      "outputs": [],
      "source": [
        "class CHOWDER(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CHOWDER, self).__init__()\n",
        "\n",
        "        # Convolutional layer\n",
        "        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2048, stride=2048)\n",
        "\n",
        "        # MLP layers with dropout\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(4, 200),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Linear(200, 100),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.fc3 = nn.Sequential(\n",
        "            nn.Linear(100, 1),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## CONVOLUTION LAYER\n",
        "        conv_output = self.conv(x)\n",
        "\n",
        "        # Calculate L2-norm on weights in the convolutional layer\n",
        "        l2_reg = 0.0\n",
        "        for param in self.conv.parameters():\n",
        "            l2_reg += torch.sum(param ** 2)\n",
        "\n",
        "        ## MINMAX LAYER\n",
        "\n",
        "        # Sort each row of the conv layer (each row is a sample)\n",
        "        sorted_output, _ = torch.sort(conv_output, dim=2)\n",
        "\n",
        "        # Number of top instances and negative evidence\n",
        "        R = 2\n",
        "\n",
        "        # Select the first two and last two sorted outputs\n",
        "        selected_output = sorted_output[:, :, :R]\n",
        "        a0 = torch.cat((selected_output, sorted_output[:, :, -R:]), dim=2)\n",
        "\n",
        "        a0 = a0.squeeze()\n",
        "\n",
        "        ## MLP\n",
        "\n",
        "        # Layer 1\n",
        "        z1 = self.fc1(a0)\n",
        "        a1 = torch.sigmoid(z1)\n",
        "\n",
        "        # Layer 2\n",
        "        z2 = self.fc2(a1)\n",
        "        a2 = torch.sigmoid(z2)\n",
        "\n",
        "        # Output layer\n",
        "        z3 = self.fc3(a2)\n",
        "        output = torch.sigmoid(z3)\n",
        "\n",
        "        return output, l2_reg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_model = CHOWDER()\n",
        "\n",
        "demo_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfK_D8ki0_8a",
        "outputId": "161e005c-122b-42e7-fed8-7d2061813b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CHOWDER(\n",
              "  (conv): Conv1d(1, 1, kernel_size=(2048,), stride=(2048,))\n",
              "  (fc1): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=200, bias=True)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (fc3): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9FI8PUMSAHW"
      },
      "source": [
        "## Setup Hyperparameters and Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwA77N-8SDvp"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "BATCH_SIZE = 10\n",
        "LR = 0.001\n",
        "EPOCHS = 30\n",
        "NUM_ENSEMBLE_MODELS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHLHzyStTH9S"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_tensor, target_tensor):\n",
        "        self.data = data_tensor\n",
        "        self.target = target_tensor\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# Create custom datasets\n",
        "train_dataset = CustomDataset(X_train_tensor, torch.Tensor(y_train))\n",
        "val_dataset = CustomDataset(X_val_tensor, torch.Tensor(y_val))\n",
        "\n",
        "# Create DataLoader\n",
        "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pusa-2_1Tbs5"
      },
      "outputs": [],
      "source": [
        "# Free Up Memory\n",
        "del X_train_tensor\n",
        "del X_val_tensor\n",
        "del y_train\n",
        "del y_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3_KACwOkeNm"
      },
      "source": [
        "## Train Model and Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X_vyiqBkdj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47833f97-daaa-4b0c-b38f-76bf3ef42ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ----- Model 1 -----\n",
            "Epoch [1/30] - Train Loss: 0.7366 Train AUC Score: 0.4549         Val Loss: 0.6863 Val AUC Score: 0.6748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30] - Train Loss: 0.6866 Train AUC Score: 0.4751         Val Loss: 0.6735 Val AUC Score: 0.5193\n",
            "Epoch [3/30] - Train Loss: 0.6947 Train AUC Score: 0.4312         Val Loss: 0.6909 Val AUC Score: 0.4982\n",
            "Epoch [4/30] - Train Loss: 0.7097 Train AUC Score: 0.4484         Val Loss: 0.6636 Val AUC Score: 0.5424\n",
            "Epoch [5/30] - Train Loss: 0.6703 Train AUC Score: 0.5443         Val Loss: 0.6730 Val AUC Score: 0.6011\n",
            "Epoch [6/30] - Train Loss: 0.6631 Train AUC Score: 0.5460         Val Loss: 0.6734 Val AUC Score: 0.3965\n",
            "Epoch [7/30] - Train Loss: 0.6890 Train AUC Score: 0.4377         Val Loss: 0.6686 Val AUC Score: 0.6142\n",
            "Epoch [8/30] - Train Loss: 0.6717 Train AUC Score: 0.5049         Val Loss: 0.6569 Val AUC Score: 0.6920\n",
            "Epoch [9/30] - Train Loss: 0.7019 Train AUC Score: 0.4390         Val Loss: 0.6751 Val AUC Score: 0.5486\n",
            "Epoch [10/30] - Train Loss: 0.6976 Train AUC Score: 0.3924         Val Loss: 0.6713 Val AUC Score: 0.4420\n",
            "Epoch [11/30] - Train Loss: 0.6682 Train AUC Score: 0.5739         Val Loss: 0.6652 Val AUC Score: 0.4709\n",
            "Epoch [12/30] - Train Loss: 0.6721 Train AUC Score: 0.5090         Val Loss: 0.6692 Val AUC Score: 0.4278\n",
            "Epoch [13/30] - Train Loss: 0.6783 Train AUC Score: 0.5138         Val Loss: 0.6738 Val AUC Score: 0.4200\n",
            "Epoch [14/30] - Train Loss: 0.7021 Train AUC Score: 0.4538         Val Loss: 0.6819 Val AUC Score: 0.5119\n",
            "Epoch [15/30] - Train Loss: 0.6932 Train AUC Score: 0.4728         Val Loss: 0.6789 Val AUC Score: 0.4864\n",
            "Epoch [16/30] - Train Loss: 0.6806 Train AUC Score: 0.5098         Val Loss: 0.6590 Val AUC Score: 0.3854\n",
            "Epoch [17/30] - Train Loss: 0.6642 Train AUC Score: 0.5553         Val Loss: 0.6636 Val AUC Score: 0.4516\n",
            "Epoch [18/30] - Train Loss: 0.6827 Train AUC Score: 0.5196         Val Loss: 0.6627 Val AUC Score: 0.4702\n",
            "Epoch [19/30] - Train Loss: 0.6962 Train AUC Score: 0.4614         Val Loss: 0.6725 Val AUC Score: 0.5026\n",
            "Epoch [20/30] - Train Loss: 0.7032 Train AUC Score: 0.4267         Val Loss: 0.6672 Val AUC Score: 0.4260\n",
            "Epoch [21/30] - Train Loss: 0.6789 Train AUC Score: 0.5268         Val Loss: 0.6632 Val AUC Score: 0.5035\n",
            "Epoch [22/30] - Train Loss: 0.6941 Train AUC Score: 0.4965         Val Loss: 0.6699 Val AUC Score: 0.5342\n",
            "Epoch [23/30] - Train Loss: 0.6905 Train AUC Score: 0.4288         Val Loss: 0.6575 Val AUC Score: 0.6726\n",
            "Epoch [24/30] - Train Loss: 0.6761 Train AUC Score: 0.4953         Val Loss: 0.6635 Val AUC Score: 0.4867\n",
            "Epoch [25/30] - Train Loss: 0.6806 Train AUC Score: 0.5004         Val Loss: 0.6673 Val AUC Score: 0.4338\n",
            "Epoch [26/30] - Train Loss: 0.6838 Train AUC Score: 0.4823         Val Loss: 0.6569 Val AUC Score: 0.4487\n",
            "Epoch [27/30] - Train Loss: 0.6676 Train AUC Score: 0.5140         Val Loss: 0.6470 Val AUC Score: 0.4286\n",
            "Epoch [28/30] - Train Loss: 0.6715 Train AUC Score: 0.5222         Val Loss: 0.6664 Val AUC Score: 0.5556\n",
            "Epoch [29/30] - Train Loss: 0.6674 Train AUC Score: 0.5227         Val Loss: 0.6471 Val AUC Score: 0.5339\n",
            "Epoch [30/30] - Train Loss: 0.6719 Train AUC Score: 0.5425         Val Loss: 0.6496 Val AUC Score: 0.2927\n",
            "\n",
            " ----- Model 2 -----\n",
            "Epoch [1/30] - Train Loss: 0.7265 Train AUC Score: 0.5008         Val Loss: 0.6639 Val AUC Score: 0.5253\n",
            "Epoch [2/30] - Train Loss: 0.6865 Train AUC Score: 0.4574         Val Loss: 0.6559 Val AUC Score: 0.5305\n",
            "Epoch [3/30] - Train Loss: 0.6860 Train AUC Score: 0.5011         Val Loss: 0.6485 Val AUC Score: 0.6414\n",
            "Epoch [4/30] - Train Loss: 0.7033 Train AUC Score: 0.4087         Val Loss: 0.6735 Val AUC Score: 0.4308\n",
            "Epoch [5/30] - Train Loss: 0.6949 Train AUC Score: 0.4795         Val Loss: 0.6627 Val AUC Score: 0.4427\n",
            "Epoch [6/30] - Train Loss: 0.6639 Train AUC Score: 0.5362         Val Loss: 0.6654 Val AUC Score: 0.4723\n",
            "Epoch [7/30] - Train Loss: 0.6809 Train AUC Score: 0.4631         Val Loss: 0.6564 Val AUC Score: 0.4747\n",
            "Epoch [8/30] - Train Loss: 0.6825 Train AUC Score: 0.4712         Val Loss: 0.6733 Val AUC Score: 0.3488\n",
            "Epoch [9/30] - Train Loss: 0.6696 Train AUC Score: 0.5167         Val Loss: 0.6649 Val AUC Score: 0.5875\n",
            "Epoch [10/30] - Train Loss: 0.6892 Train AUC Score: 0.4276         Val Loss: 0.6621 Val AUC Score: 0.5068\n",
            "Epoch [11/30] - Train Loss: 0.6883 Train AUC Score: 0.4671         Val Loss: 0.6767 Val AUC Score: 0.4901\n",
            "Epoch [12/30] - Train Loss: 0.6887 Train AUC Score: 0.4973         Val Loss: 0.6408 Val AUC Score: 0.7183\n",
            "Epoch [13/30] - Train Loss: 0.6930 Train AUC Score: 0.4631         Val Loss: 0.6503 Val AUC Score: 0.4894\n",
            "Epoch [14/30] - Train Loss: 0.6629 Train AUC Score: 0.5731         Val Loss: 0.6488 Val AUC Score: 0.4826\n",
            "Epoch [15/30] - Train Loss: 0.6569 Train AUC Score: 0.5771         Val Loss: 0.6750 Val AUC Score: 0.5268\n",
            "Epoch [16/30] - Train Loss: 0.6691 Train AUC Score: 0.5376         Val Loss: 0.6477 Val AUC Score: 0.5533\n",
            "Epoch [17/30] - Train Loss: 0.6789 Train AUC Score: 0.5261         Val Loss: 0.6529 Val AUC Score: 0.6354\n",
            "Epoch [18/30] - Train Loss: 0.6850 Train AUC Score: 0.4950         Val Loss: 0.6620 Val AUC Score: 0.5021\n",
            "Epoch [19/30] - Train Loss: 0.6840 Train AUC Score: 0.4922         Val Loss: 0.6730 Val AUC Score: 0.5649\n",
            "Epoch [20/30] - Train Loss: 0.6858 Train AUC Score: 0.4779         Val Loss: 0.6631 Val AUC Score: 0.6686\n",
            "Epoch [21/30] - Train Loss: 0.6703 Train AUC Score: 0.5253         Val Loss: 0.6734 Val AUC Score: 0.4652\n",
            "Epoch [22/30] - Train Loss: 0.6785 Train AUC Score: 0.4299         Val Loss: 0.6655 Val AUC Score: 0.4271\n",
            "Epoch [23/30] - Train Loss: 0.6831 Train AUC Score: 0.4713         Val Loss: 0.6620 Val AUC Score: 0.5516\n",
            "Epoch [24/30] - Train Loss: 0.6805 Train AUC Score: 0.5188         Val Loss: 0.6634 Val AUC Score: 0.4446\n",
            "Epoch [25/30] - Train Loss: 0.7016 Train AUC Score: 0.4335         Val Loss: 0.6646 Val AUC Score: 0.5339\n",
            "Epoch [26/30] - Train Loss: 0.6761 Train AUC Score: 0.5173         Val Loss: 0.6696 Val AUC Score: 0.4129\n",
            "Epoch [27/30] - Train Loss: 0.6699 Train AUC Score: 0.5376         Val Loss: 0.6732 Val AUC Score: 0.5149\n",
            "Epoch [28/30] - Train Loss: 0.6834 Train AUC Score: 0.5398         Val Loss: 0.6633 Val AUC Score: 0.5060\n",
            "Epoch [29/30] - Train Loss: 0.6871 Train AUC Score: 0.4875         Val Loss: 0.6637 Val AUC Score: 0.4985\n",
            "Epoch [30/30] - Train Loss: 0.6811 Train AUC Score: 0.4983         Val Loss: 0.6620 Val AUC Score: 0.3125\n",
            "\n",
            " ----- Model 3 -----\n",
            "Epoch [1/30] - Train Loss: 0.7296 Train AUC Score: 0.4650         Val Loss: 0.6620 Val AUC Score: 0.4688\n",
            "Epoch [2/30] - Train Loss: 0.6497 Train AUC Score: 0.6008         Val Loss: 0.6771 Val AUC Score: 0.7312\n",
            "Epoch [3/30] - Train Loss: 0.6911 Train AUC Score: 0.4957         Val Loss: 0.6805 Val AUC Score: 0.3669\n",
            "Epoch [4/30] - Train Loss: 0.6768 Train AUC Score: 0.5156         Val Loss: 0.6730 Val AUC Score: 0.5238\n",
            "Epoch [5/30] - Train Loss: 0.6723 Train AUC Score: 0.5163         Val Loss: 0.6648 Val AUC Score: 0.5490\n",
            "Epoch [6/30] - Train Loss: 0.6979 Train AUC Score: 0.4531         Val Loss: 0.6903 Val AUC Score: 0.5461\n",
            "Epoch [7/30] - Train Loss: 0.6845 Train AUC Score: 0.4648         Val Loss: 0.6517 Val AUC Score: 0.4000\n",
            "Epoch [8/30] - Train Loss: 0.6755 Train AUC Score: 0.5258         Val Loss: 0.6623 Val AUC Score: 0.4212\n",
            "Epoch [9/30] - Train Loss: 0.6711 Train AUC Score: 0.5403         Val Loss: 0.6414 Val AUC Score: 0.3705\n",
            "Epoch [10/30] - Train Loss: 0.6772 Train AUC Score: 0.4998         Val Loss: 0.6616 Val AUC Score: 0.2882\n",
            "Epoch [11/30] - Train Loss: 0.6805 Train AUC Score: 0.4699         Val Loss: 0.6649 Val AUC Score: 0.6116\n",
            "Epoch [12/30] - Train Loss: 0.6698 Train AUC Score: 0.5421         Val Loss: 0.6540 Val AUC Score: 0.4247\n",
            "Epoch [13/30] - Train Loss: 0.6796 Train AUC Score: 0.4806         Val Loss: 0.6692 Val AUC Score: 0.5104\n",
            "Epoch [14/30] - Train Loss: 0.6807 Train AUC Score: 0.4652         Val Loss: 0.6825 Val AUC Score: 0.4479\n",
            "Epoch [15/30] - Train Loss: 0.6951 Train AUC Score: 0.4302         Val Loss: 0.6780 Val AUC Score: 0.5549\n",
            "Epoch [16/30] - Train Loss: 0.6854 Train AUC Score: 0.4898         Val Loss: 0.6672 Val AUC Score: 0.5004\n",
            "Epoch [17/30] - Train Loss: 0.6893 Train AUC Score: 0.4805         Val Loss: 0.6698 Val AUC Score: 0.3713\n",
            "Epoch [18/30] - Train Loss: 0.6927 Train AUC Score: 0.5066         Val Loss: 0.6749 Val AUC Score: 0.3915\n",
            "Epoch [19/30] - Train Loss: 0.6792 Train AUC Score: 0.5142         Val Loss: 0.6425 Val AUC Score: 0.6064\n",
            "Epoch [20/30] - Train Loss: 0.6885 Train AUC Score: 0.4795         Val Loss: 0.6540 Val AUC Score: 0.5379\n",
            "Epoch [21/30] - Train Loss: 0.6797 Train AUC Score: 0.4993         Val Loss: 0.6656 Val AUC Score: 0.3363\n",
            "Epoch [22/30] - Train Loss: 0.6805 Train AUC Score: 0.5095         Val Loss: 0.6620 Val AUC Score: 0.3593\n",
            "Epoch [23/30] - Train Loss: 0.6842 Train AUC Score: 0.4914         Val Loss: 0.6734 Val AUC Score: 0.5216\n",
            "Epoch [24/30] - Train Loss: 0.6859 Train AUC Score: 0.4635         Val Loss: 0.6749 Val AUC Score: 0.4398\n",
            "Epoch [25/30] - Train Loss: 0.6871 Train AUC Score: 0.4775         Val Loss: 0.6706 Val AUC Score: 0.5974\n",
            "Epoch [26/30] - Train Loss: 0.6775 Train AUC Score: 0.5272         Val Loss: 0.6621 Val AUC Score: 0.3661\n",
            "Epoch [27/30] - Train Loss: 0.6533 Train AUC Score: 0.5996         Val Loss: 0.6761 Val AUC Score: 0.6190\n",
            "Epoch [28/30] - Train Loss: 0.7130 Train AUC Score: 0.4227         Val Loss: 0.6727 Val AUC Score: 0.5092\n",
            "Epoch [29/30] - Train Loss: 0.6737 Train AUC Score: 0.5600         Val Loss: 0.6566 Val AUC Score: 0.5429\n",
            "Epoch [30/30] - Train Loss: 0.6726 Train AUC Score: 0.5103         Val Loss: 0.6818 Val AUC Score: 0.5219\n",
            "\n",
            " ----- Model 4 -----\n",
            "Epoch [1/30] - Train Loss: 0.7329 Train AUC Score: 0.4890         Val Loss: 0.6667 Val AUC Score: 0.4017\n",
            "Epoch [2/30] - Train Loss: 0.6848 Train AUC Score: 0.4745         Val Loss: 0.6656 Val AUC Score: 0.5141\n",
            "Epoch [3/30] - Train Loss: 0.6837 Train AUC Score: 0.4885         Val Loss: 0.6821 Val AUC Score: 0.4793\n",
            "Epoch [4/30] - Train Loss: 0.6883 Train AUC Score: 0.4238         Val Loss: 0.6682 Val AUC Score: 0.3442\n",
            "Epoch [5/30] - Train Loss: 0.6823 Train AUC Score: 0.4685         Val Loss: 0.6701 Val AUC Score: 0.5582\n",
            "Epoch [6/30] - Train Loss: 0.6975 Train AUC Score: 0.4662         Val Loss: 0.6733 Val AUC Score: 0.5417\n",
            "Epoch [7/30] - Train Loss: 0.6833 Train AUC Score: 0.4734         Val Loss: 0.6500 Val AUC Score: 0.4021\n",
            "Epoch [8/30] - Train Loss: 0.6598 Train AUC Score: 0.6000         Val Loss: 0.6378 Val AUC Score: 0.4860\n",
            "Epoch [9/30] - Train Loss: 0.6837 Train AUC Score: 0.4851         Val Loss: 0.6762 Val AUC Score: 0.6112\n",
            "Epoch [10/30] - Train Loss: 0.6936 Train AUC Score: 0.4952         Val Loss: 0.6736 Val AUC Score: 0.5600\n",
            "Epoch [11/30] - Train Loss: 0.6855 Train AUC Score: 0.5005         Val Loss: 0.6584 Val AUC Score: 0.5104\n",
            "Epoch [12/30] - Train Loss: 0.6751 Train AUC Score: 0.5255         Val Loss: 0.6498 Val AUC Score: 0.4182\n",
            "Epoch [13/30] - Train Loss: 0.6962 Train AUC Score: 0.4726         Val Loss: 0.6660 Val AUC Score: 0.4211\n",
            "Epoch [14/30] - Train Loss: 0.6593 Train AUC Score: 0.5728         Val Loss: 0.6750 Val AUC Score: 0.5711\n",
            "Epoch [15/30] - Train Loss: 0.6808 Train AUC Score: 0.5207         Val Loss: 0.6524 Val AUC Score: 0.6244\n",
            "Epoch [16/30] - Train Loss: 0.6777 Train AUC Score: 0.5269         Val Loss: 0.6415 Val AUC Score: 0.6198\n",
            "Epoch [17/30] - Train Loss: 0.6589 Train AUC Score: 0.5850         Val Loss: 0.6734 Val AUC Score: 0.4167\n",
            "Epoch [18/30] - Train Loss: 0.6785 Train AUC Score: 0.5165         Val Loss: 0.6709 Val AUC Score: 0.6659\n",
            "Epoch [19/30] - Train Loss: 0.6892 Train AUC Score: 0.4972         Val Loss: 0.6716 Val AUC Score: 0.5376\n",
            "Epoch [20/30] - Train Loss: 0.6914 Train AUC Score: 0.4886         Val Loss: 0.6777 Val AUC Score: 0.5565\n",
            "Epoch [21/30] - Train Loss: 0.6807 Train AUC Score: 0.4532         Val Loss: 0.6640 Val AUC Score: 0.5182\n",
            "Epoch [22/30] - Train Loss: 0.6790 Train AUC Score: 0.4778         Val Loss: 0.6734 Val AUC Score: 0.4918\n",
            "Epoch [23/30] - Train Loss: 0.6945 Train AUC Score: 0.4165         Val Loss: 0.6594 Val AUC Score: 0.4580\n",
            "Epoch [24/30] - Train Loss: 0.6794 Train AUC Score: 0.4819         Val Loss: 0.6731 Val AUC Score: 0.3281\n",
            "Epoch [25/30] - Train Loss: 0.6720 Train AUC Score: 0.5114         Val Loss: 0.6644 Val AUC Score: 0.7634\n",
            "Epoch [26/30] - Train Loss: 0.6709 Train AUC Score: 0.5164         Val Loss: 0.6335 Val AUC Score: 0.3832\n",
            "Epoch [27/30] - Train Loss: 0.6880 Train AUC Score: 0.5070         Val Loss: 0.6639 Val AUC Score: 0.6026\n",
            "Epoch [28/30] - Train Loss: 0.6917 Train AUC Score: 0.4446         Val Loss: 0.6821 Val AUC Score: 0.5151\n",
            "Epoch [29/30] - Train Loss: 0.6753 Train AUC Score: 0.5118         Val Loss: 0.6661 Val AUC Score: 0.5290\n",
            "Epoch [30/30] - Train Loss: 0.6911 Train AUC Score: 0.4207         Val Loss: 0.6752 Val AUC Score: 0.6296\n",
            "\n",
            " ----- Model 5 -----\n",
            "Epoch [1/30] - Train Loss: 0.7299 Train AUC Score: 0.5038         Val Loss: 0.6730 Val AUC Score: 0.4660\n",
            "Epoch [2/30] - Train Loss: 0.6937 Train AUC Score: 0.5087         Val Loss: 0.6733 Val AUC Score: 0.5193\n",
            "Epoch [3/30] - Train Loss: 0.6824 Train AUC Score: 0.4989         Val Loss: 0.6724 Val AUC Score: 0.4191\n",
            "Epoch [4/30] - Train Loss: 0.6963 Train AUC Score: 0.4397         Val Loss: 0.6901 Val AUC Score: 0.4094\n",
            "Epoch [5/30] - Train Loss: 0.6806 Train AUC Score: 0.4846         Val Loss: 0.6618 Val AUC Score: 0.3239\n",
            "Epoch [6/30] - Train Loss: 0.6706 Train AUC Score: 0.5231         Val Loss: 0.6703 Val AUC Score: 0.4315\n",
            "Epoch [7/30] - Train Loss: 0.6826 Train AUC Score: 0.4996         Val Loss: 0.6555 Val AUC Score: 0.4807\n",
            "Epoch [8/30] - Train Loss: 0.6862 Train AUC Score: 0.4502         Val Loss: 0.6753 Val AUC Score: 0.5477\n",
            "Epoch [9/30] - Train Loss: 0.6938 Train AUC Score: 0.4688         Val Loss: 0.6759 Val AUC Score: 0.5909\n",
            "Epoch [10/30] - Train Loss: 0.6961 Train AUC Score: 0.4455         Val Loss: 0.6870 Val AUC Score: 0.6466\n",
            "Epoch [11/30] - Train Loss: 0.6852 Train AUC Score: 0.4638         Val Loss: 0.6731 Val AUC Score: 0.5357\n",
            "Epoch [12/30] - Train Loss: 0.6852 Train AUC Score: 0.4673         Val Loss: 0.6785 Val AUC Score: 0.4323\n",
            "Epoch [13/30] - Train Loss: 0.6857 Train AUC Score: 0.5182         Val Loss: 0.6631 Val AUC Score: 0.4021\n",
            "Epoch [14/30] - Train Loss: 0.6802 Train AUC Score: 0.4902         Val Loss: 0.6550 Val AUC Score: 0.6751\n",
            "Epoch [15/30] - Train Loss: 0.6899 Train AUC Score: 0.4680         Val Loss: 0.6779 Val AUC Score: 0.5006\n",
            "Epoch [16/30] - Train Loss: 0.6814 Train AUC Score: 0.4656         Val Loss: 0.6723 Val AUC Score: 0.5298\n",
            "Epoch [17/30] - Train Loss: 0.6860 Train AUC Score: 0.5287         Val Loss: 0.6675 Val AUC Score: 0.6421\n",
            "Epoch [18/30] - Train Loss: 0.6673 Train AUC Score: 0.5323         Val Loss: 0.6617 Val AUC Score: 0.4509\n",
            "Epoch [19/30] - Train Loss: 0.6965 Train AUC Score: 0.4387         Val Loss: 0.6750 Val AUC Score: 0.4952\n",
            "Epoch [20/30] - Train Loss: 0.6910 Train AUC Score: 0.5289         Val Loss: 0.6711 Val AUC Score: 0.3991\n",
            "Epoch [21/30] - Train Loss: 0.6697 Train AUC Score: 0.5630         Val Loss: 0.6503 Val AUC Score: 0.3824\n",
            "Epoch [22/30] - Train Loss: 0.6869 Train AUC Score: 0.4917         Val Loss: 0.6536 Val AUC Score: 0.6164\n",
            "Epoch [23/30] - Train Loss: 0.6716 Train AUC Score: 0.5433         Val Loss: 0.6658 Val AUC Score: 0.3408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30] - Train Loss: 0.6964 Train AUC Score: 0.4552         Val Loss: 0.6801 Val AUC Score: 0.4799\n",
            "Epoch [25/30] - Train Loss: 0.6883 Train AUC Score: 0.4669         Val Loss: 0.6702 Val AUC Score: 0.4015\n",
            "Epoch [26/30] - Train Loss: 0.6928 Train AUC Score: 0.4764         Val Loss: 0.6804 Val AUC Score: 0.3193\n",
            "Epoch [27/30] - Train Loss: 0.6854 Train AUC Score: 0.4905         Val Loss: 0.6752 Val AUC Score: 0.4176\n",
            "Epoch [28/30] - Train Loss: 0.6757 Train AUC Score: 0.5160         Val Loss: 0.6485 Val AUC Score: 0.7545\n",
            "Epoch [29/30] - Train Loss: 0.6617 Train AUC Score: 0.5900         Val Loss: 0.6396 Val AUC Score: 0.5094\n",
            "Epoch [30/30] - Train Loss: 0.6837 Train AUC Score: 0.4428         Val Loss: 0.6754 Val AUC Score: 0.4414\n",
            "\n",
            " ----- Model 6 -----\n",
            "Epoch [1/30] - Train Loss: 0.7276 Train AUC Score: 0.5499         Val Loss: 0.6638 Val AUC Score: 0.4321\n",
            "Epoch [2/30] - Train Loss: 0.6812 Train AUC Score: 0.4634         Val Loss: 0.6578 Val AUC Score: 0.4836\n",
            "Epoch [3/30] - Train Loss: 0.6781 Train AUC Score: 0.5343         Val Loss: 0.6616 Val AUC Score: 0.4415\n",
            "Epoch [4/30] - Train Loss: 0.7029 Train AUC Score: 0.4111         Val Loss: 0.6839 Val AUC Score: 0.5143\n",
            "Epoch [5/30] - Train Loss: 0.6813 Train AUC Score: 0.5177         Val Loss: 0.6630 Val AUC Score: 0.6701\n",
            "Epoch [6/30] - Train Loss: 0.6805 Train AUC Score: 0.5242         Val Loss: 0.6795 Val AUC Score: 0.5235\n",
            "Epoch [7/30] - Train Loss: 0.6912 Train AUC Score: 0.4625         Val Loss: 0.6536 Val AUC Score: 0.4276\n",
            "Epoch [8/30] - Train Loss: 0.6788 Train AUC Score: 0.5082         Val Loss: 0.6629 Val AUC Score: 0.2500\n",
            "Epoch [9/30] - Train Loss: 0.6905 Train AUC Score: 0.4416         Val Loss: 0.6637 Val AUC Score: 0.6448\n",
            "Epoch [10/30] - Train Loss: 0.6725 Train AUC Score: 0.5137         Val Loss: 0.6622 Val AUC Score: 0.5245\n",
            "Epoch [11/30] - Train Loss: 0.6848 Train AUC Score: 0.4585         Val Loss: 0.6592 Val AUC Score: 0.5293\n",
            "Epoch [12/30] - Train Loss: 0.6738 Train AUC Score: 0.5473         Val Loss: 0.6820 Val AUC Score: 0.4562\n",
            "Epoch [13/30] - Train Loss: 0.6872 Train AUC Score: 0.4853         Val Loss: 0.6731 Val AUC Score: 0.4442\n",
            "Epoch [14/30] - Train Loss: 0.6810 Train AUC Score: 0.4946         Val Loss: 0.6552 Val AUC Score: 0.2979\n",
            "Epoch [15/30] - Train Loss: 0.6836 Train AUC Score: 0.4977         Val Loss: 0.6536 Val AUC Score: 0.5291\n",
            "Epoch [16/30] - Train Loss: 0.6684 Train AUC Score: 0.5138         Val Loss: 0.6729 Val AUC Score: 0.6562\n",
            "Epoch [17/30] - Train Loss: 0.6917 Train AUC Score: 0.4541         Val Loss: 0.6696 Val AUC Score: 0.2836\n",
            "Epoch [18/30] - Train Loss: 0.6718 Train AUC Score: 0.5298         Val Loss: 0.6492 Val AUC Score: 0.5908\n",
            "Epoch [19/30] - Train Loss: 0.6767 Train AUC Score: 0.4482         Val Loss: 0.6731 Val AUC Score: 0.3706\n",
            "Epoch [20/30] - Train Loss: 0.6973 Train AUC Score: 0.4416         Val Loss: 0.6756 Val AUC Score: 0.3765\n",
            "Epoch [21/30] - Train Loss: 0.6758 Train AUC Score: 0.4989         Val Loss: 0.6624 Val AUC Score: 0.5414\n",
            "Epoch [22/30] - Train Loss: 0.6712 Train AUC Score: 0.5285         Val Loss: 0.6550 Val AUC Score: 0.4524\n",
            "Epoch [23/30] - Train Loss: 0.6823 Train AUC Score: 0.4959         Val Loss: 0.6640 Val AUC Score: 0.5119\n",
            "Epoch [24/30] - Train Loss: 0.6948 Train AUC Score: 0.4595         Val Loss: 0.6659 Val AUC Score: 0.4896\n",
            "Epoch [25/30] - Train Loss: 0.6781 Train AUC Score: 0.5177         Val Loss: 0.6616 Val AUC Score: 0.5824\n",
            "Epoch [26/30] - Train Loss: 0.6914 Train AUC Score: 0.4708         Val Loss: 0.6654 Val AUC Score: 0.5543\n",
            "Epoch [27/30] - Train Loss: 0.6927 Train AUC Score: 0.4704         Val Loss: 0.6571 Val AUC Score: 0.4129\n",
            "Epoch [28/30] - Train Loss: 0.6888 Train AUC Score: 0.4945         Val Loss: 0.6664 Val AUC Score: 0.5041\n",
            "Epoch [29/30] - Train Loss: 0.6847 Train AUC Score: 0.4532         Val Loss: 0.6554 Val AUC Score: 0.5446\n",
            "Epoch [30/30] - Train Loss: 0.6808 Train AUC Score: 0.5025         Val Loss: 0.6735 Val AUC Score: 0.5290\n",
            "\n",
            " ----- Model 7 -----\n",
            "Epoch [1/30] - Train Loss: 0.7532 Train AUC Score: 0.4846         Val Loss: 0.6878 Val AUC Score: 0.4437\n",
            "Epoch [2/30] - Train Loss: 0.6825 Train AUC Score: 0.4731         Val Loss: 0.6730 Val AUC Score: 0.5312\n",
            "Epoch [3/30] - Train Loss: 0.6829 Train AUC Score: 0.5103         Val Loss: 0.6647 Val AUC Score: 0.5804\n",
            "Epoch [4/30] - Train Loss: 0.6877 Train AUC Score: 0.4512         Val Loss: 0.6761 Val AUC Score: 0.3973\n",
            "Epoch [5/30] - Train Loss: 0.6818 Train AUC Score: 0.5075         Val Loss: 0.6501 Val AUC Score: 0.4229\n",
            "Epoch [6/30] - Train Loss: 0.6806 Train AUC Score: 0.5089         Val Loss: 0.6827 Val AUC Score: 0.4676\n",
            "Epoch [7/30] - Train Loss: 0.6800 Train AUC Score: 0.4982         Val Loss: 0.6780 Val AUC Score: 0.6158\n",
            "Epoch [8/30] - Train Loss: 0.6881 Train AUC Score: 0.4628         Val Loss: 0.6688 Val AUC Score: 0.6079\n",
            "Epoch [9/30] - Train Loss: 0.6725 Train AUC Score: 0.5509         Val Loss: 0.6740 Val AUC Score: 0.3505\n",
            "Epoch [10/30] - Train Loss: 0.6685 Train AUC Score: 0.5640         Val Loss: 0.6618 Val AUC Score: 0.4884\n",
            "Epoch [11/30] - Train Loss: 0.6851 Train AUC Score: 0.5347         Val Loss: 0.6552 Val AUC Score: 0.5129\n",
            "Epoch [12/30] - Train Loss: 0.6851 Train AUC Score: 0.4986         Val Loss: 0.6773 Val AUC Score: 0.6988\n",
            "Epoch [13/30] - Train Loss: 0.6739 Train AUC Score: 0.5489         Val Loss: 0.6619 Val AUC Score: 0.5223\n",
            "Epoch [14/30] - Train Loss: 0.6934 Train AUC Score: 0.4578         Val Loss: 0.6704 Val AUC Score: 0.5579\n",
            "Epoch [15/30] - Train Loss: 0.6911 Train AUC Score: 0.5058         Val Loss: 0.6653 Val AUC Score: 0.5057\n",
            "Epoch [16/30] - Train Loss: 0.6866 Train AUC Score: 0.4955         Val Loss: 0.6652 Val AUC Score: 0.2944\n",
            "Epoch [17/30] - Train Loss: 0.6575 Train AUC Score: 0.6173         Val Loss: 0.6631 Val AUC Score: 0.4448\n",
            "Epoch [18/30] - Train Loss: 0.6770 Train AUC Score: 0.4982         Val Loss: 0.6772 Val AUC Score: 0.6507\n",
            "Epoch [19/30] - Train Loss: 0.6717 Train AUC Score: 0.5516         Val Loss: 0.6514 Val AUC Score: 0.4088\n",
            "Epoch [20/30] - Train Loss: 0.6546 Train AUC Score: 0.5537         Val Loss: 0.6505 Val AUC Score: 0.5824\n",
            "Epoch [21/30] - Train Loss: 0.6955 Train AUC Score: 0.4661         Val Loss: 0.6852 Val AUC Score: 0.4345\n",
            "Epoch [22/30] - Train Loss: 0.6781 Train AUC Score: 0.5139         Val Loss: 0.6532 Val AUC Score: 0.5441\n",
            "Epoch [23/30] - Train Loss: 0.6678 Train AUC Score: 0.5616         Val Loss: 0.6620 Val AUC Score: 0.4184\n",
            "Epoch [24/30] - Train Loss: 0.6719 Train AUC Score: 0.5415         Val Loss: 0.6665 Val AUC Score: 0.5636\n",
            "Epoch [25/30] - Train Loss: 0.6739 Train AUC Score: 0.5696         Val Loss: 0.6409 Val AUC Score: 0.4912\n",
            "Epoch [26/30] - Train Loss: 0.6765 Train AUC Score: 0.4846         Val Loss: 0.6746 Val AUC Score: 0.4925\n",
            "Epoch [27/30] - Train Loss: 0.6650 Train AUC Score: 0.5703         Val Loss: 0.6859 Val AUC Score: 0.4687\n",
            "Epoch [28/30] - Train Loss: 0.6682 Train AUC Score: 0.5740         Val Loss: 0.6505 Val AUC Score: 0.3467\n",
            "Epoch [29/30] - Train Loss: 0.6754 Train AUC Score: 0.5303         Val Loss: 0.6629 Val AUC Score: 0.4963\n",
            "Epoch [30/30] - Train Loss: 0.6741 Train AUC Score: 0.5052         Val Loss: 0.6627 Val AUC Score: 0.5498\n",
            "\n",
            " ----- Model 8 -----\n",
            "Epoch [1/30] - Train Loss: 0.7434 Train AUC Score: 0.4825         Val Loss: 0.6819 Val AUC Score: 0.6322\n",
            "Epoch [2/30] - Train Loss: 0.6889 Train AUC Score: 0.4555         Val Loss: 0.6573 Val AUC Score: 0.4365\n",
            "Epoch [3/30] - Train Loss: 0.6890 Train AUC Score: 0.4668         Val Loss: 0.6550 Val AUC Score: 0.3594\n",
            "Epoch [4/30] - Train Loss: 0.6953 Train AUC Score: 0.4727         Val Loss: 0.6796 Val AUC Score: 0.5632\n"
          ]
        }
      ],
      "source": [
        "# Define loss function and optimizer\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Create an ensemble of models\n",
        "ensemble_models = []\n",
        "\n",
        "for _ in range(NUM_ENSEMBLE_MODELS):\n",
        "\n",
        "    # Initialize the model\n",
        "    model = CHOWDER()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    ensemble_models.append((model, optimizer))\n",
        "\n",
        "# Setup model counter\n",
        "model_counter = 1\n",
        "\n",
        "# Training and validation loops for each model in the ensemble\n",
        "for model, optimizer in ensemble_models:\n",
        "\n",
        "    print(f'\\n ----- Model {model_counter} -----')\n",
        "    model_counter += 1\n",
        "\n",
        "    # Loop thorugh each epoch\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        ## Training loop\n",
        "\n",
        "        # Put model in train mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize loss, AUC and count\n",
        "        total_loss = 0.0\n",
        "        auroc_hist_train = 0.0\n",
        "        total_count = 0.0\n",
        "\n",
        "        # Train in batches\n",
        "        for batch_x, batch_y in train_dl:\n",
        "\n",
        "            batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Make predictions and get L2-norm from conv layer\n",
        "            pred, weight_decay = model(batch_x_transformed)\n",
        "\n",
        "            # Calculate loss\n",
        "            batch_y = batch_y.view(-1, 1) # Reshape batch_y from (10) to (10,1)\n",
        "            loss = loss_function(pred, batch_y) + (0.5*weight_decay)\n",
        "\n",
        "            # Calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Make step in gradient descent\n",
        "            optimizer.step()\n",
        "\n",
        "            # Add to loss counter for this epoch\n",
        "            total_loss += loss.item() * len(batch_y)\n",
        "            total_count += len(batch_y)\n",
        "\n",
        "            # Calculate AUC for batch\n",
        "            auroc_hist_train += torchmetrics.AUROC(task=\"binary\")(pred, batch_y).item() * len(batch_y)\n",
        "\n",
        "        # Calculate loss and AUC per sample\n",
        "        train_average_loss = total_loss / total_count\n",
        "        train_average_auc = auroc_hist_train/ total_count\n",
        "\n",
        "\n",
        "        ## Validation loop\n",
        "\n",
        "        # Put model in evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Fix gradients (only using model to predict)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Initialize loss, AUC and count\n",
        "            total_loss = 0.0\n",
        "            auroc_hist_val = 0.0\n",
        "            total_count = 0.0\n",
        "\n",
        "            # Validate in batches\n",
        "            for batch_x, batch_y in val_dl:\n",
        "\n",
        "                batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "                # Make predictions\n",
        "                val_pred, _ = model(batch_x_transformed)\n",
        "\n",
        "                # Calculate loss\n",
        "                batch_y = batch_y.view(-1, 1) # Reshape batch_y from (10) to (10,1)\n",
        "                loss = loss_function(val_pred, batch_y)\n",
        "\n",
        "                # Add to loss for this epoch\n",
        "                total_loss += loss.item() * len(batch_y)\n",
        "                total_count += len(batch_y)\n",
        "\n",
        "                # Calculate AUC for batch\n",
        "                auroc_hist_val += torchmetrics.AUROC(task=\"binary\")(val_pred, batch_y).item() * len(batch_y)\n",
        "\n",
        "        # Calculate loss and AUC per sample\n",
        "        val_average_loss = total_loss / total_count\n",
        "        val_average_auc =  auroc_hist_val / total_count\n",
        "\n",
        "        # Print results from each epoch\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {train_average_loss:.4f} Train AUC Score: {train_average_auc:.4f} \\\n",
        "        Val Loss: {val_average_loss:.4f} Val AUC Score: {val_average_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLJ3f4HD63Zb"
      },
      "outputs": [],
      "source": [
        "# After training all models, calculate the ensemble AUC\n",
        "\n",
        "# Store predictions and labels\n",
        "ensemble_predictions = []\n",
        "val_labels = []\n",
        "\n",
        "# Do not change gradients\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Loop through each model\n",
        "    for model, _ in ensemble_models:\n",
        "\n",
        "        # Put model in evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Get predictions on the validation dataset\n",
        "        predictions = []\n",
        "        batch_labels = []  # Create a list to store labels for each batch\n",
        "\n",
        "        for batch_x, batch_y in val_dl:\n",
        "\n",
        "            batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "            # Make predictions\n",
        "            pred, _, _ = model(batch_x_transformed)\n",
        "            # Save predictions\n",
        "            predictions.append(pred)\n",
        "\n",
        "            # Store val labels for this batch\n",
        "            batch_labels.append(batch_y)\n",
        "\n",
        "        # Concatenate the labels for this model\n",
        "        batch_labels = torch.cat(batch_labels, dim=0)\n",
        "        val_labels.append(batch_labels)\n",
        "\n",
        "        predictions = torch.cat(predictions)\n",
        "        ensemble_predictions.append(predictions)\n",
        "\n",
        "# Concatenate all the validation labels\n",
        "val_labels = torch.cat(val_labels, dim=0)\n",
        "\n",
        "# Average the predictions from all models\n",
        "ensemble_predictions = torch.stack(ensemble_predictions)\n",
        "average_predictions = torch.mean(ensemble_predictions, dim=0)\n",
        "\n",
        "# Calculate the AUC score based on the averaged predictions\n",
        "average_auc = torchmetrics.AUROC(task=\"binary\")(average_predictions, val_labels).item()\n",
        "print(f\"Ensemble AUC Score: {average_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eCI-fHc1Oeb"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU3UREXZ1QH_"
      },
      "outputs": [],
      "source": [
        "## Setup DataLoaders\n",
        "\n",
        "# Create a dummy y for test set\n",
        "y_test_dummy = torch.zeros(len(X_test_tensor),)\n",
        "\n",
        "# Create custom datasets\n",
        "test_dataset = CustomDataset(X_test_tensor, y_test_dummy)\n",
        "\n",
        "# Create DataLoader\n",
        "test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Merge them using ConcatDataset\n",
        "dev_dataset = ConcatDataset([train_dataset, val_dataset])\n",
        "\n",
        "# Create a DataLoader for the merged dataset\n",
        "dev_dl = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaEiv9s03HQA"
      },
      "outputs": [],
      "source": [
        "# Free Up Memory\n",
        "del X_test_tensor\n",
        "del train_dataset\n",
        "del val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcMwUt273UCM"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Create an ensemble of models\n",
        "ensemble_models = []\n",
        "\n",
        "for _ in range(NUM_ENSEMBLE_MODELS):\n",
        "\n",
        "    # Initialize the model\n",
        "    model = CHOWDER()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    ensemble_models.append((model, optimizer))\n",
        "\n",
        "# Setup model counter\n",
        "model_counter = 1\n",
        "\n",
        "# Training loops for each model in the ensemble\n",
        "for model, optimizer in ensemble_models:\n",
        "\n",
        "    print(f'\\n ----- Model {model_counter} -----')\n",
        "    model_counter += 1\n",
        "\n",
        "    # Loop thorugh each epoch\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        ## Training loop\n",
        "\n",
        "        # Put model in train mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize loss, AUC and count\n",
        "        total_loss = 0.0\n",
        "        auroc_hist_train = 0.0\n",
        "        total_count = 0.0\n",
        "\n",
        "        # Train in batches\n",
        "        for batch_x, batch_y in dev_dl:\n",
        "\n",
        "            # Add a dimension for channel numbers\n",
        "            batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Add a dimension for channel numbers\n",
        "            batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "            # Make predictions and get L2-norm from conv layer\n",
        "            pred, L2_term = model(batch_x_transformed)\n",
        "\n",
        "            # Calculate loss\n",
        "            batch_y = batch_y.view(-1, 1) # Reshape batch_y from (10) to (10,1)\n",
        "            loss = loss_function(pred, batch_y) + (0.5*L2_term)\n",
        "\n",
        "            # Calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Make step in gradient descent\n",
        "            optimizer.step()\n",
        "\n",
        "            # Add to loss counter for this epoch\n",
        "            total_loss += loss.item() * len(batch_y)\n",
        "            total_count += len(batch_y)\n",
        "\n",
        "            # Calculate AUC for batch\n",
        "            auroc_hist_train += torchmetrics.AUROC(task=\"binary\")(pred, batch_y).item() * len(batch_y)\n",
        "\n",
        "        # Calculate loss and AUC per sample\n",
        "        train_average_loss = total_loss / total_count\n",
        "        train_average_auc = auroc_hist_train/ total_count\n",
        "\n",
        "        # Print results from each epoch\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Train Loss: {train_average_loss:.4f} Train AUC Score: {train_average_auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLCvU2N73s6M"
      },
      "outputs": [],
      "source": [
        "# After training all models, calculate the ensemble AUC\n",
        "\n",
        "# Store predictions and labels\n",
        "ensemble_predictions = np.zeros((len(test_dataset), len(ensemble_models)))\n",
        "\n",
        "# Do not change gradients\n",
        "with torch.no_grad():\n",
        "\n",
        "    model_counter = 0\n",
        "\n",
        "    # Loop through each model\n",
        "    for model, _ in ensemble_models:\n",
        "\n",
        "        # Put model in evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Get predictions on the validation dataset\n",
        "        predictions = np.empty((0, 1))\n",
        "\n",
        "        for batch_x, _ in test_dl:\n",
        "\n",
        "            extra = 10 - len(batch_x)\n",
        "\n",
        "            # If batch size is smaller than 10, pad rows in batch_x with 0s\n",
        "            if extra > 0:\n",
        "                pad_tensor = torch.zeros((extra,) + batch_x.shape[1:], dtype=batch_x.dtype)\n",
        "                batch_x = torch.cat((batch_x, pad_tensor), dim=0)\n",
        "\n",
        "            # Add a dimension for channel numbers\n",
        "            batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "            # Make predictions\n",
        "            pred, _ = model(batch_x_transformed)\n",
        "\n",
        "            # Save predictions\n",
        "            pred_numpy = pred.numpy()\n",
        "            predictions = np.concatenate((predictions, pred_numpy), axis=0)\n",
        "\n",
        "            if extra > 0:\n",
        "              predictions = predictions[:-extra]\n",
        "\n",
        "        ensemble_predictions[:, model_counter] = predictions.squeeze()\n",
        "        model_counter += 1\n",
        "\n",
        "# Average the predictions from all models\n",
        "average_prediction = np.mean(ensemble_predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULTV1bdoWvXq"
      },
      "outputs": [],
      "source": [
        "# Load metadata about each sample\n",
        "data_path = '/content/drive/My Drive/Breast_Cancer_Detection/Data/'\n",
        "df_test = pd.read_csv(data_path + \"test_metadata.csv\")\n",
        "\n",
        "# Join sample ID metadata with probability prediction\n",
        "CHOWDER_submission = pd.DataFrame( {\"Sample ID\": df_test[\"Sample ID\"].values, \"Target\": average_prediction}).sort_values(\"Sample ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uGJVXsOW7h-"
      },
      "outputs": [],
      "source": [
        "def sanity_checks(submission):\n",
        "    assert all(submission[\"Target\"].between(0, 1)), \"`Target` values must be in [0, 1]\"\n",
        "    assert submission.shape == (149, 2), \"Your submission file must be of shape (149, 2)\"\n",
        "    assert list(submission.columns) == [\"Sample ID\", \"Target\",], \"Your submission file must have columns `Sample ID` and `Target`\"\n",
        "\n",
        "sanity_checks(CHOWDER_submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhV0ZzImXBOC"
      },
      "outputs": [],
      "source": [
        "submission_path = '/content/drive/My Drive/Breast_Cancer_Detection/Predictions/'\n",
        "\n",
        "CHOWDER_submission.to_csv(submission_path + \"CHOWDER_submission_base.csv\", index=None)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}