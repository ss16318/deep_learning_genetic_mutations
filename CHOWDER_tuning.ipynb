{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7a7WuSCGBiS"
      },
      "source": [
        "# CHOWDER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTUvo2GGELp"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7K98CEankGG",
        "outputId": "963405b9-377b-4998-e246-c7b784294396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRdeZmxRF6lv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, ConcatDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ym0jJzmGMwX",
        "outputId": "c24d5190-4c16-4677-cc70-fa94f90ef333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEP9wThKGNmv"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA9sRTmAGPbH"
      },
      "outputs": [],
      "source": [
        "processed_data_path = '/content/drive/My Drive/Breast_Cancer_Detection/Processed_Data/'\n",
        "\n",
        "X_dev = np.load(processed_data_path + 'X_dev.npy')\n",
        "y_dev = np.load(processed_data_path + 'y_dev.npy')\n",
        "\n",
        "X_test = np.load(processed_data_path + 'X_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UZ5pixlHaP_"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvD3AJlWHbl6"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.15, stratify=y_dev, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCQyfA4KGiJT"
      },
      "source": [
        "## Standardize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rrujd_x7GmCJ"
      },
      "outputs": [],
      "source": [
        "def X_standardize(X_train, X_val, X_test):\n",
        "\n",
        "    feature_mean = np.mean(X_train)\n",
        "    feature_std = np.std(X_train)\n",
        "\n",
        "    X_train_scaled = (X_train - feature_mean) / feature_std\n",
        "    X_val_scaled = (X_val - feature_mean) / feature_std\n",
        "    X_test_scaled = (X_test - feature_mean) / feature_std\n",
        "\n",
        "    return X_train_scaled, X_val_scaled, X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5r1BHVpzHwEP"
      },
      "outputs": [],
      "source": [
        "X_train_scaled, X_val_scaled, X_test_scaled = X_standardize(X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypElU9wJJO2X"
      },
      "source": [
        "## Convert to Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHP07ms3I22G"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.Tensor(X_train_scaled)\n",
        "X_val_tensor = torch.Tensor(X_val_scaled)\n",
        "X_test_tensor = torch.Tensor(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FLD-9qYJTJ9"
      },
      "outputs": [],
      "source": [
        "# Delete redundant variables to free up memory\n",
        "del X_train_scaled\n",
        "del X_val_scaled\n",
        "del X_test_scaled\n",
        "del X_train\n",
        "del X_val\n",
        "del X_test\n",
        "del X_dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvkzmqLUJ9o3"
      },
      "source": [
        "## CHOWDER Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs8Yoh9SJ_wP"
      },
      "outputs": [],
      "source": [
        "class CHOWDER(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CHOWDER, self).__init__()\n",
        "\n",
        "        # Convolutional layer\n",
        "        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2048, stride=2048)\n",
        "\n",
        "        self.fc1 = nn.Linear(4, 1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "\n",
        "        # Set std to the square root of the number of edges\n",
        "        std_conv = 2048**(-0.5)\n",
        "        # Initialize weights with random normal values for the convolutional layer\n",
        "        nn.init.normal_(self.conv.weight, mean=0.0, std=std_conv)\n",
        "        nn.init.constant_(self.conv.bias, 0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## CONVOLUTION LAYER\n",
        "        conv_output = self.conv(x)\n",
        "\n",
        "        # Calculate L2-norm on weights in the convolutional layer\n",
        "        l2_reg = 0.0\n",
        "        for param in self.conv.parameters():\n",
        "            l2_reg += torch.sum(param ** 2)\n",
        "\n",
        "        ## MINMAX LAYER\n",
        "\n",
        "        # Sort each row of the conv layer (each row is a sample)\n",
        "        sorted_output, _ = torch.sort(conv_output, dim=2)\n",
        "\n",
        "        # Number of top instances and negative evidence\n",
        "        R = 2\n",
        "\n",
        "        # Select the first two and last two sorted outputs\n",
        "        selected_output = sorted_output[:, :, :R]\n",
        "        a0 = torch.cat((selected_output, sorted_output[:, :, -R:]), dim=2)\n",
        "\n",
        "        a0 = a0.squeeze()\n",
        "\n",
        "        z1 = self.fc1(a0)\n",
        "\n",
        "        output = torch.sigmoid(z1)\n",
        "\n",
        "        return output, l2_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfK_D8ki0_8a",
        "outputId": "e16a2385-163c-482f-db80-dacc7883ff5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CHOWDER(\n",
              "  (conv): Conv1d(1, 1, kernel_size=(2048,), stride=(2048,))\n",
              "  (fc1): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "demo_model = CHOWDER()\n",
        "\n",
        "demo_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9FI8PUMSAHW"
      },
      "source": [
        "## Setup Hyperparameters and Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwA77N-8SDvp"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "NUM_ENSEMBLE_MODELS = 10\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHLHzyStTH9S"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_tensor, target_tensor):\n",
        "        self.data = data_tensor\n",
        "        self.target = target_tensor\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "# Create custom datasets\n",
        "train_dataset = CustomDataset(X_train_tensor, torch.Tensor(y_train))\n",
        "val_dataset = CustomDataset(X_val_tensor, torch.Tensor(y_val))\n",
        "\n",
        "# Create DataLoader\n",
        "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pusa-2_1Tbs5"
      },
      "outputs": [],
      "source": [
        "# Free Up Memory\n",
        "del X_train_tensor\n",
        "del X_val_tensor\n",
        "del y_train\n",
        "del y_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3_KACwOkeNm"
      },
      "source": [
        "## Train Model and Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X_vyiqBkdj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12220919-babd-47a4-f4e8-0d70c778b44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ----- Model 1 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 2 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 3 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 4 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 5 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 6 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 7 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 8 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 9 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 10 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "LR:0.0001 Epochs:30 L2:0.1 --- Ensemble AUC Score: 0.3500\n",
            "\n",
            " ----- Model 1 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 2 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 3 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 4 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 5 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 6 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 7 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 8 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 9 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "\n",
            " ----- Model 10 -----\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "LR:0.0001 Epochs:30 L2:0.5 --- Ensemble AUC Score: 0.3250\n"
          ]
        }
      ],
      "source": [
        "LR = [0.0001]\n",
        "EPOCHS = [30]\n",
        "L2 = [0.1, 0.5]\n",
        "\n",
        "for lr in LR:\n",
        "    for epochs in EPOCHS:\n",
        "        for l2 in L2:\n",
        "\n",
        "            # Create an ensemble of models\n",
        "            ensemble_models = []\n",
        "\n",
        "            for _ in range(NUM_ENSEMBLE_MODELS):\n",
        "\n",
        "                # Initialize the model\n",
        "                model = CHOWDER()\n",
        "\n",
        "                # Define optimizer\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "                ensemble_models.append((model, optimizer))\n",
        "\n",
        "            # Setup model counter\n",
        "            model_counter = 1\n",
        "\n",
        "            # Training and validation loops for each model in the ensemble\n",
        "            for model, optimizer in ensemble_models:\n",
        "\n",
        "                print(f'\\n ----- Model {model_counter} -----')\n",
        "                model_counter += 1\n",
        "\n",
        "                # Loop through each epoch\n",
        "                for epoch in range(epochs):\n",
        "                    ## Training loop\n",
        "\n",
        "                    # Put model in train mode\n",
        "                    model.train()\n",
        "\n",
        "                    # Train in batches\n",
        "                    for batch_x, batch_y in train_dl:\n",
        "\n",
        "                        batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "                        # Zero gradients\n",
        "                        optimizer.zero_grad()\n",
        "\n",
        "                        # Make predictions and get L2-norm from the conv layer\n",
        "                        pred, weight_decay = model(batch_x_transformed)\n",
        "\n",
        "                        # Calculate loss\n",
        "                        batch_y = batch_y.view(-1, 1) # Reshape batch_y from (10) to (10,1)\n",
        "                        loss = loss_function(pred, batch_y) + (l2 * weight_decay)\n",
        "\n",
        "                        # Calculate gradients\n",
        "                        loss.backward()\n",
        "\n",
        "                        # Make a step in gradient descent\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # Print results from each epoch\n",
        "                    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "            # After training all models, calculate the ensemble AUC\n",
        "\n",
        "            # Store predictions and labels\n",
        "            ensemble_predictions = []\n",
        "            val_labels = []\n",
        "\n",
        "            # Do not change gradients\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # Loop through each model\n",
        "                for model, _ in ensemble_models:\n",
        "\n",
        "                    # Put model in evaluation mode\n",
        "                    model.eval()\n",
        "\n",
        "                    # Get predictions on the validation dataset\n",
        "                    predictions = []\n",
        "                    batch_labels = []  # Create a list to store labels for each batch\n",
        "\n",
        "                    for batch_x, batch_y in val_dl:\n",
        "\n",
        "                        batch_x_transformed = batch_x.unsqueeze(1)\n",
        "\n",
        "                        # Make predictions\n",
        "                        pred, _ = model(batch_x_transformed)\n",
        "                        # Save predictions\n",
        "                        predictions.append(pred)\n",
        "\n",
        "                        # Store val labels for this batch\n",
        "                        batch_labels.append(batch_y)\n",
        "\n",
        "                    # Concatenate the labels for this model\n",
        "                    batch_labels = torch.cat(batch_labels, dim=0)\n",
        "                    val_labels.append(batch_labels)\n",
        "\n",
        "                    predictions = torch.cat(predictions)\n",
        "                    ensemble_predictions.append(predictions)\n",
        "\n",
        "            # Concatenate all the validation labels\n",
        "            val_labels = torch.cat(val_labels, dim=0)\n",
        "\n",
        "            # Average the predictions from all models\n",
        "            ensemble_predictions = torch.stack(ensemble_predictions)\n",
        "            average_predictions = torch.mean(ensemble_predictions, dim=0)\n",
        "\n",
        "            # Calculate the AUC score based on the averaged predictions\n",
        "            average_auc = torchmetrics.AUROC(task=\"binary\")(average_predictions, val_labels).item()\n",
        "            print(f\"LR:{lr} Epochs:{epochs} L2:{l2} --- Ensemble AUC Score: {average_auc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLJ3f4HD63Zb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}